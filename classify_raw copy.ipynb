{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(samples): 5411\n",
      "len(set(labels)): 46\n",
      "train_Y\n",
      "Number 6: 89, Number 39: 87, Number 33: 75, Number 7: 101, Number 26: 115, Number 19: 67, Number 43: 90, Number 28: 63, Number 12: 59, Number 1: 126, Number 17: 97, Number 40: 101, Number 44: 111, Number 41: 95, Number 34: 115, Number 38: 111, Number 24: 108, Number 16: 101, Number 8: 118, Number 3: 100, Number 21: 64, Number 29: 120, Number 4: 102, Number 36: 112, Number 14: 91, Number 18: 96, Number 31: 115, Number 11: 67, Number 15: 49, Number 42: 102, Number 9: 81, Number 27: 76, Number 45: 129, Number 2: 91, Number 10: 73, Number 5: 112, Number 20: 94, Number 32: 104, Number 30: 124, Number 37: 112, Number 23: 14, Number 25: 70, Number 22: 56, Number 35: 118, Number 0: 105, Number 13: 122\n",
      "test_Y\n",
      "Number 43: 18, Number 3: 30, Number 25: 24, Number 28: 13, Number 31: 21, Number 10: 17, Number 40: 25, Number 0: 19, Number 34: 29, Number 9: 27, Number 35: 33, Number 38: 38, Number 44: 33, Number 20: 27, Number 21: 20, Number 42: 25, Number 45: 33, Number 16: 17, Number 7: 14, Number 1: 25, Number 32: 24, Number 36: 28, Number 18: 23, Number 26: 33, Number 29: 33, Number 24: 26, Number 39: 18, Number 41: 34, Number 30: 30, Number 19: 14, Number 5: 29, Number 4: 24, Number 14: 25, Number 22: 14, Number 17: 27, Number 13: 27, Number 11: 10, Number 15: 13, Number 37: 39, Number 8: 34, Number 23: 4, Number 33: 15, Number 6: 21, Number 12: 15, Number 2: 21, Number 27: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mambauser/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 2.29s: train loss 2.447936, train acc 0.298, test loss 1.662402, test acc 0.496\n",
      "Epoch 2 1.99s: train loss 1.340932, train acc 0.580, test loss 1.121276, test acc 0.638\n",
      "Epoch 3 1.99s: train loss 1.005132, train acc 0.682, test loss 1.025619, test acc 0.667\n",
      "Epoch 4 2.06s: train loss 0.704471, train acc 0.771, test loss 0.814274, test acc 0.735\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "from MMClassifyFunc.train import Trainer\n",
    "from MMClassifyFunc.models import CustomResNet\n",
    "from MMClassifyFunc.data_preprocess import get_loader_hdf5\n",
    "from MMClassifyFunc.data_read import get_data_hdf5_wly\n",
    "from MMClassifyFunc.visualization import visualize_results, visualize_predict\n",
    "\n",
    "h5_file_path = \"/home/mambauser/MMClassify/data/data_processed_noise_mma.hdf5\"\n",
    "in_channels = 1\n",
    "\n",
    "samples, labels = get_data_hdf5_wly(\n",
    "    h5_file_path=h5_file_path,\n",
    "    in_channels=in_channels,\n",
    "    # wordIndex=[1],\n",
    "    # fileIndex=list(range(0,10))+list(range(12,30))+list(range(32,40)),\n",
    "    # personIndex=list(range(5)),\n",
    "    # txIndex=list(range(0, 8)),\n",
    "    useLog=True,\n",
    "    timeLength=200,\n",
    ")\n",
    "\n",
    "print(\"len(samples): {}\".format(len(samples)))\n",
    "print(\"len(set(labels)): {}\".format(len(set(labels))))\n",
    "\n",
    "trainloader, testloader = get_loader_hdf5(samples=samples, labels=labels)\n",
    "\n",
    "# classifier\n",
    "classifier = CustomResNet(\n",
    "    in_channels=in_channels,\n",
    "    num_classes=len(set(labels)),\n",
    "    weights=models.ResNet18_Weights.DEFAULT,\n",
    "    model=\"resnet18\",\n",
    ")\n",
    "\n",
    "# optimizers\n",
    "lr = 1e-3\n",
    "betas = (0.5, 0.99)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=lr, betas=betas)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# train model\n",
    "NUM_INPUTS = 1\n",
    "epochs = 50\n",
    "\n",
    "trainer = Trainer(\n",
    "    num_inputs=NUM_INPUTS,\n",
    "    classifier=classifier,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    print_every=1,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    use_cuda=torch.cuda.is_available(),\n",
    "    use_scheduler=False,\n",
    ")\n",
    "\n",
    "trainer.train(trainloader=trainloader, testloader=testloader, epochs=epochs)\n",
    "\n",
    "visualize_results(trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "from MMClassifyFunc.train import Trainer\n",
    "from MMClassifyFunc.models import CustomResNet\n",
    "from MMClassifyFunc.data_preprocess import get_loader_hdf5, get_loader_all_hdf5\n",
    "from MMClassifyFunc.data_read import get_data_hdf5_wly\n",
    "from MMClassifyFunc.visualization import visualize_results, visualize_predict\n",
    "\n",
    "\n",
    "h5_file_path = \"/home/mambauser/MMClassify/data/data_processed_noise_mma.hdf5\"\n",
    "in_channels = 1\n",
    "\n",
    "samples, labels = get_data_hdf5_wly(\n",
    "    h5_file_path=h5_file_path,\n",
    "    in_channels=in_channels,\n",
    "    wordIndex=[0],\n",
    "    # fileIndex=list(range(0,10))+list(range(12,30))+list(range(32,40)),\n",
    "    # personIndex=[0],\n",
    "    txIndex=[8,9],\n",
    "    useLog=True,\n",
    "    timeLength=100,\n",
    ")\n",
    "\n",
    "print(\"len(samples): {}\".format(len(samples)))\n",
    "print(\"len(set(labels)): {}\".format(len(set(labels))))\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataloader = get_loader_all_hdf5(samples, labels)\n",
    "\n",
    "# classifier\n",
    "trainer.classifier.eval()\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# classifier.to(device)\n",
    "trainer.classifier.to(device)\n",
    "\n",
    "# Prepare for evaluation\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(dataloader, desc=\"Processing batches\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = trainer.classifier(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "visualize_predict(all_labels, all_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
